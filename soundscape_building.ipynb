{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "181b6da5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU: NVIDIA GeForce RTX 5070 Ti Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "import torch\n",
    "import datafawn\n",
    "importlib.reload(datafawn)\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "# Check GPU\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print(f\"Using GPU: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print(\"CUDA not available, using CPU\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a87f974c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============== POSE ESTIMATOR =============== #\n",
    "dlc_estimator = datafawn.DeepLabCutPoseEstimator(\n",
    "    model_name='superanimal_quadruped',\n",
    "    detector_name='fasterrcnn_resnet50_fpn_v2',\n",
    "    hrnet_model='hrnet_w32',\n",
    "    max_individuals=1,\n",
    "    pcutoff=0.15,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "# =============== POSTPROCESSORS =============== #\n",
    "rel_paws = ['front_left_paw_rel', 'front_right_paw_rel', 'back_left_paw_rel', 'back_right_paw_rel']\n",
    "reference_map = {\n",
    "    'back_base': ['front_left_paw', 'front_right_paw'],\n",
    "    'tail_base': ['back_left_paw', 'back_right_paw']\n",
    "}\n",
    "\n",
    "rel_pp = datafawn.RelativePawPositionPostprocessor()\n",
    "error_pp = datafawn.ErrorPostprocessor(\n",
    "    bodyparts=rel_paws,\n",
    "    use_velocity=True,\n",
    "    use_likelihood=True,\n",
    "    use_distance=True,\n",
    "    velocity_kwargs={'threshold_pixels': 50, 'window_size': 5},\n",
    "    likelihood_kwargs={'min_likelihood': 0.5},\n",
    "    distance_kwargs={'reference_map': reference_map, 'max_distance': 300}\n",
    ")\n",
    "\n",
    "# =============== EVENT EXTRACTOR =============== #\n",
    "zeni_extractor = datafawn.ZeniExtractor(\n",
    "    smooth_window_size=5,\n",
    "    prominence_percentage=0.05,\n",
    "    orientation_likelihood_threshold=0.0,\n",
    "    orientation_smooth_window_size=15,\n",
    "    show_plots=False\n",
    ")\n",
    "\n",
    "# =============== SOUNDSCAPE GENERATOR =============== #\n",
    "SOUNDSCAPE_CONFIG = {\n",
    "    'event_sound_map': {\n",
    "        'front_left_paw_strike': Path('sounds/409837__datafawn__digital/838432__silverillusionist__glitch-faulty-core-2.wav'),\n",
    "        'front_right_paw_strike': Path('sounds/409837__datafawn__digital/839817__silverillusionist__glitch-faulty-core-5.wav'),\n",
    "        'back_left_paw_strike': Path('sounds/409837__datafawn__digital/839954__kerdwyn__single-note-d.wav'),\n",
    "        'back_right_paw_strike': Path('sounds/409837__datafawn__digital/840060__pedr01__notification.wav')\n",
    "    },\n",
    "    'backing_track': Path('sounds/839814__apintofmild__industrial-plant-atmos-2-of-4.wav'),\n",
    "    'volume': {\n",
    "        'backing_track': 0.10,\n",
    "        'event_sounds': 0.65,\n",
    "        'original_video': 4.0\n",
    "    }\n",
    "}\n",
    "# SOUNDSCAPE_CONFIG = {\n",
    "#     'event_sound_map': {\n",
    "#         'front_left_paw_strike': Path('data_example/sounds/22415__anthousai__wind-chimes/398494__anthousai__wind-chimes-single-01.wav'),\n",
    "#         'front_right_paw_strike': Path('data_example/sounds/22415__anthousai__wind-chimes/398493__anthousai__wind-chimes-single-02.wav'),\n",
    "#         'back_left_paw_strike': Path('data_example/sounds/22415__anthousai__wind-chimes/398492__anthousai__wind-chimes-single-03.wav'),\n",
    "#         'back_right_paw_strike': Path('data_example/sounds/22415__anthousai__wind-chimes/398496__anthousai__wind-chimes-single-04.wav')\n",
    "#     },\n",
    "#     'backing_track': Path('data_example/sounds/22415__anthousai__wind-chimes/398495__anthousai__wind-chimes-rough.wav'),\n",
    "#     'volume': {\n",
    "#         'backing_track': 0.10,\n",
    "#         'event_sounds': 0.65,\n",
    "#         'original_video': 4.0\n",
    "#     }\n",
    "# }\n",
    "ss_generator = datafawn.SoundScapeFromConfig(soundscape_config=SOUNDSCAPE_CONFIG)\n",
    "\n",
    "ss_auto = datafawn.SoundScapeAuto()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45b1fa01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the FULL pipeline with all components\n",
    "pipeline = datafawn.EventDetectionPipeline(\n",
    "    pose_estimator=dlc_estimator,\n",
    "    postprocessors=[rel_pp, error_pp],\n",
    "    event_extractors=[zeni_extractor],\n",
    "    # soundscape_generators=[ss_generator]\n",
    "    soundscape_generators=[ss_auto]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9eeffc98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Run full pipeline from raw video\n",
    "# RAW_VIDEO_PATH = 'data/raw_videos/inspo_tiktok.mov'\n",
    "# OUTPUT_DIR = 'data/tiktok'\n",
    "\n",
    "# results = pipeline.run(\n",
    "#     video_path=RAW_VIDEO_PATH,\n",
    "#     output_dir=OUTPUT_DIR,\n",
    "#     soundscape_input_video=\"pose_est\"  # Use the labeled video for soundscape\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e012f4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading video: data\\tiktok\\pose_estimation\\inspo_tiktok_superanimal_quadruped_hrnet_w32_fasterrcnn_resnet50_fpn_v2__labeled_before_adapt.mp4\n",
      "Video FPS: 30.0\n",
      "Video duration: 28.07 seconds\n",
      "\n",
      "Found 12 back feet note files: ['C5.wav', 'D5.wav', 'E5.wav', 'F5.wav', 'G5.wav', 'A5.wav', 'B5.wav', 'C6.wav', 'D6.wav', 'E6.wav', 'F6.wav', 'G6.wav']\n",
      "Found 12 front feet note files: ['C6.wav', 'D6.wav', 'E6.wav', 'F6.wav', 'G6.wav', 'A6.wav', 'B6.wav', 'C7.wav', 'D7.wav', 'E7.wav', 'F7.wav', 'G7.wav']\n",
      "Speed array calculated: 740 frames\n",
      "\n",
      "============================================================\n",
      "Processing individual: animal0 (scorer: superanimal_quadruped_hrnet_w32_fasterrcnn_resnet50_fpn_v2_)\n",
      "============================================================\n",
      "\n",
      "  Processing back_right_paw_strike:\n",
      "    Found 61 strikes\n",
      "    Strike timestamps: ['1.17s', '2.10s', '2.80s']...\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "Error in file sounds\\custom_tone\\B5.wav, Accessing time t=1.00-1.00 seconds, with clip duration=0.300000 seconds, ",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOSError\u001b[39m                                   Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Partial pipeline after events are extracted\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m results = \u001b[43mpipeline\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mevents_path\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mdata/tiktok/events/events.json\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mdata/tiktok/\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43msoundscape_input_video\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mdata/tiktok/pose_estimation/inspo_tiktok_superanimal_quadruped_hrnet_w32_fasterrcnn_resnet50_fpn_v2__labeled_before_adapt.mp4\u001b[39;49m\u001b[33;43m'\u001b[39;49m\n\u001b[32m      6\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jexia\\OneDrive\\Documents\\projects\\datafawn\\datafawn\\pipeline.py:419\u001b[39m, in \u001b[36mEventDetectionPipeline.run\u001b[39m\u001b[34m(self, video_path, pose_data, pose_data_path, postprocessed_data, postprocessed_data_path, events, events_path, output_dir, soundscape_input_video, **kwargs)\u001b[39m\n\u001b[32m    415\u001b[39m     gen_output_path = soundscape_output / \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgen_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_output.mp4\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    417\u001b[39m \u001b[38;5;66;03m# Pass events structure with individuals intact\u001b[39;00m\n\u001b[32m    418\u001b[39m \u001b[38;5;66;03m# Structure: {(scorer, individual): {event_type: [frames]}}\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m419\u001b[39m result = \u001b[43mgenerator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    420\u001b[39m \u001b[43m    \u001b[49m\u001b[43msoundscape_video_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    421\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_event_results\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    422\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgen_output_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    423\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43msoundscape_kwargs\u001b[49m\n\u001b[32m    424\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    425\u001b[39m \u001b[38;5;28mself\u001b[39m._soundscape_results[gen_name] = result\n\u001b[32m    427\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m gen_output_path:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jexia\\OneDrive\\Documents\\projects\\datafawn\\datafawn\\soundscape_gen.py:60\u001b[39m, in \u001b[36mSoundScapeAuto.generate\u001b[39m\u001b[34m(self, input_video_path, events_dict, output_path)\u001b[39m\n\u001b[32m     27\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate\u001b[39m(\n\u001b[32m     28\u001b[39m     \u001b[38;5;28mself\u001b[39m, \n\u001b[32m     29\u001b[39m     input_video_path: Union[\u001b[38;5;28mstr\u001b[39m, Path], \n\u001b[32m     30\u001b[39m     events_dict: Dict[\u001b[38;5;28mstr\u001b[39m, Any], \n\u001b[32m     31\u001b[39m     output_path: Optional[Union[\u001b[38;5;28mstr\u001b[39m, Path]] = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m     32\u001b[39m ) -> \u001b[38;5;28mstr\u001b[39m:\n\u001b[32m     33\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     34\u001b[39m \u001b[33;03m    Add sounds for detected events to a video.\u001b[39;00m\n\u001b[32m     35\u001b[39m \u001b[33;03m    \u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     58\u001b[39m \u001b[33;03m        Path to the output video file\u001b[39;00m\n\u001b[32m     59\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m60\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msoundscape_auto\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     61\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_video_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_video_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     62\u001b[39m \u001b[43m        \u001b[49m\u001b[43mevents_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mevents_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     63\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_path\u001b[49m\n\u001b[32m     64\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jexia\\OneDrive\\Documents\\projects\\datafawn\\datafawn\\soundscape\\soundscape_auto.py:219\u001b[39m, in \u001b[36msoundscape_auto\u001b[39m\u001b[34m(input_video_path, events_dict, notes_folder, output_path, std_dev, speed_threshold)\u001b[39m\n\u001b[32m    217\u001b[39m \u001b[38;5;66;03m# Step 1: Reverse first (if needed) - operates on full clip\u001b[39;00m\n\u001b[32m    218\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m should_reverse:\n\u001b[32m--> \u001b[39m\u001b[32m219\u001b[39m     note_clip = \u001b[43maudio_time_mirror\u001b[49m\u001b[43m(\u001b[49m\u001b[43moriginal_clip\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    220\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    221\u001b[39m     note_clip = original_clip\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jexia\\OneDrive\\Documents\\projects\\datafawn\\datafawn\\soundscape\\soundscape_auto.py:35\u001b[39m, in \u001b[36maudio_time_mirror\u001b[39m\u001b[34m(clip)\u001b[39m\n\u001b[32m     30\u001b[39m fps = clip.fps\n\u001b[32m     32\u001b[39m \u001b[38;5;66;03m# Use to_soundarray() - this is more reliable than get_frame(tt)\u001b[39;00m\n\u001b[32m     33\u001b[39m \u001b[38;5;66;03m# because it explicitly reads the entire clip into memory,\u001b[39;00m\n\u001b[32m     34\u001b[39m \u001b[38;5;66;03m# avoiding moviepy's internal reader seeking/buffering issues\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m35\u001b[39m audio_array = \u001b[43mclip\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_soundarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfps\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     37\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m audio_array \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(audio_array) == \u001b[32m0\u001b[39m:\n\u001b[32m     38\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mCould not extract audio array from clip\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jexia\\anaconda3\\envs\\DEEPLABCUT\\Lib\\site-packages\\decorator.py:235\u001b[39m, in \u001b[36mdecorate.<locals>.fun\u001b[39m\u001b[34m(*args, **kw)\u001b[39m\n\u001b[32m    233\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kwsyntax:\n\u001b[32m    234\u001b[39m     args, kw = fix(args, kw, sig)\n\u001b[32m--> \u001b[39m\u001b[32m235\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcaller\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m(\u001b[49m\u001b[43mextras\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jexia\\anaconda3\\envs\\DEEPLABCUT\\Lib\\site-packages\\moviepy\\decorators.py:53\u001b[39m, in \u001b[36mrequires_duration\u001b[39m\u001b[34m(func, clip, *args, **kwargs)\u001b[39m\n\u001b[32m     51\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mAttribute \u001b[39m\u001b[33m'\u001b[39m\u001b[33mduration\u001b[39m\u001b[33m'\u001b[39m\u001b[33m not set\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     52\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclip\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jexia\\anaconda3\\envs\\DEEPLABCUT\\Lib\\site-packages\\moviepy\\audio\\AudioClip.py:160\u001b[39m, in \u001b[36mAudioClip.to_soundarray\u001b[39m\u001b[34m(self, tt, fps, quantize, nbytes, buffersize)\u001b[39m\n\u001b[32m    151\u001b[39m         tt = np.arange(\u001b[32m0\u001b[39m, \u001b[38;5;28mself\u001b[39m.duration, \u001b[32m1.0\u001b[39m / fps)\n\u001b[32m    152\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    153\u001b[39m \u001b[33;03melif len(tt)> 1.5*buffersize:\u001b[39;00m\n\u001b[32m    154\u001b[39m \u001b[33;03m    nchunks = int(len(tt)/buffersize+1)\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    158\u001b[39m \u001b[33;03m                      for ttc in tt_chunks])\u001b[39;00m\n\u001b[32m    159\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m160\u001b[39m snd_array = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_frame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    162\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m quantize:\n\u001b[32m    163\u001b[39m     snd_array = np.maximum(-\u001b[32m0.99\u001b[39m, np.minimum(\u001b[32m0.99\u001b[39m, snd_array))\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jexia\\anaconda3\\envs\\DEEPLABCUT\\Lib\\site-packages\\decorator.py:235\u001b[39m, in \u001b[36mdecorate.<locals>.fun\u001b[39m\u001b[34m(*args, **kw)\u001b[39m\n\u001b[32m    233\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kwsyntax:\n\u001b[32m    234\u001b[39m     args, kw = fix(args, kw, sig)\n\u001b[32m--> \u001b[39m\u001b[32m235\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcaller\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m(\u001b[49m\u001b[43mextras\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jexia\\anaconda3\\envs\\DEEPLABCUT\\Lib\\site-packages\\moviepy\\decorators.py:102\u001b[39m, in \u001b[36mpreprocess_args.<locals>.decor.<locals>.wrapper\u001b[39m\u001b[34m(func, *args, **kwargs)\u001b[39m\n\u001b[32m     90\u001b[39m new_args = [\n\u001b[32m     91\u001b[39m     (\n\u001b[32m     92\u001b[39m         preprocess_func(arg)\n\u001b[32m   (...)\u001b[39m\u001b[32m     96\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m (arg, name) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(args, argnames)\n\u001b[32m     97\u001b[39m ]\n\u001b[32m     98\u001b[39m new_kwargs = {\n\u001b[32m     99\u001b[39m     kwarg: preprocess_func(value) \u001b[38;5;28;01mif\u001b[39;00m kwarg \u001b[38;5;129;01min\u001b[39;00m varnames \u001b[38;5;28;01melse\u001b[39;00m value\n\u001b[32m    100\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m (kwarg, value) \u001b[38;5;129;01min\u001b[39;00m kwargs.items()\n\u001b[32m    101\u001b[39m }\n\u001b[32m--> \u001b[39m\u001b[32m102\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mnew_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mnew_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jexia\\anaconda3\\envs\\DEEPLABCUT\\Lib\\site-packages\\moviepy\\Clip.py:87\u001b[39m, in \u001b[36mClip.get_frame\u001b[39m\u001b[34m(self, t)\u001b[39m\n\u001b[32m     85\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m frame\n\u001b[32m     86\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m87\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mframe_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jexia\\anaconda3\\envs\\DEEPLABCUT\\Lib\\site-packages\\moviepy\\audio\\io\\AudioFileClip.py:78\u001b[39m, in \u001b[36mAudioFileClip.__init__.<locals>.<lambda>\u001b[39m\u001b[34m(t)\u001b[39m\n\u001b[32m     75\u001b[39m \u001b[38;5;28mself\u001b[39m.buffersize = \u001b[38;5;28mself\u001b[39m.reader.buffersize\n\u001b[32m     76\u001b[39m \u001b[38;5;28mself\u001b[39m.filename = filename\n\u001b[32m---> \u001b[39m\u001b[32m78\u001b[39m \u001b[38;5;28mself\u001b[39m.frame_function = \u001b[38;5;28;01mlambda\u001b[39;00m t: \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mreader\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_frame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     79\u001b[39m \u001b[38;5;28mself\u001b[39m.nchannels = \u001b[38;5;28mself\u001b[39m.reader.nchannels\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jexia\\anaconda3\\envs\\DEEPLABCUT\\Lib\\site-packages\\moviepy\\audio\\io\\readers.py:229\u001b[39m, in \u001b[36mFFMPEG_AudioReader.get_frame\u001b[39m\u001b[34m(self, tt)\u001b[39m\n\u001b[32m    226\u001b[39m     in_time_head = in_time[\u001b[32m0\u001b[39m:threshold_idx]\n\u001b[32m    227\u001b[39m     in_time_tail = in_time[threshold_idx:]\n\u001b[32m    228\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m np.concatenate(\n\u001b[32m--> \u001b[39m\u001b[32m229\u001b[39m         [\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_frame\u001b[49m\u001b[43m(\u001b[49m\u001b[43min_time_head\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28mself\u001b[39m.get_frame(in_time_tail)]\n\u001b[32m    230\u001b[39m     )\n\u001b[32m    232\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[32m0\u001b[39m <= (fr_min - \u001b[38;5;28mself\u001b[39m.buffer_startframe) < \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.buffer)):\n\u001b[32m    233\u001b[39m     \u001b[38;5;28mself\u001b[39m.buffer_around(fr_min)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jexia\\anaconda3\\envs\\DEEPLABCUT\\Lib\\site-packages\\moviepy\\audio\\io\\readers.py:209\u001b[39m, in \u001b[36mFFMPEG_AudioReader.get_frame\u001b[39m\u001b[34m(self, tt)\u001b[39m\n\u001b[32m    207\u001b[39m \u001b[38;5;66;03m# Check that the requested time is in the valid range\u001b[39;00m\n\u001b[32m    208\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m in_time.any():\n\u001b[32m--> \u001b[39m\u001b[32m209\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(\n\u001b[32m    210\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mError in file \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m, \u001b[39m\u001b[33m\"\u001b[39m % (\u001b[38;5;28mself\u001b[39m.filename)\n\u001b[32m    211\u001b[39m         + \u001b[33m\"\u001b[39m\u001b[33mAccessing time t=\u001b[39m\u001b[38;5;132;01m%.02f\u001b[39;00m\u001b[33m-\u001b[39m\u001b[38;5;132;01m%.02f\u001b[39;00m\u001b[33m seconds, \u001b[39m\u001b[33m\"\u001b[39m % (tt[\u001b[32m0\u001b[39m], tt[-\u001b[32m1\u001b[39m])\n\u001b[32m    212\u001b[39m         + \u001b[33m\"\u001b[39m\u001b[33mwith clip duration=\u001b[39m\u001b[38;5;132;01m%f\u001b[39;00m\u001b[33m seconds, \u001b[39m\u001b[33m\"\u001b[39m % \u001b[38;5;28mself\u001b[39m.duration\n\u001b[32m    213\u001b[39m     )\n\u001b[32m    215\u001b[39m \u001b[38;5;66;03m# The np.round in the next line is super-important.\u001b[39;00m\n\u001b[32m    216\u001b[39m \u001b[38;5;66;03m# Removing it results in artifacts in the noise.\u001b[39;00m\n\u001b[32m    217\u001b[39m frames = np.round((\u001b[38;5;28mself\u001b[39m.fps * tt)).astype(\u001b[38;5;28mint\u001b[39m)[in_time]\n",
      "\u001b[31mOSError\u001b[39m: Error in file sounds\\custom_tone\\B5.wav, Accessing time t=1.00-1.00 seconds, with clip duration=0.300000 seconds, "
     ]
    }
   ],
   "source": [
    "# Partial pipeline after events are extracted\n",
    "results = pipeline.run(\n",
    "    events_path='data/tiktok/events/events.json',\n",
    "    output_dir='data/tiktok/',\n",
    "    soundscape_input_video='data/tiktok/pose_estimation/inspo_tiktok_superanimal_quadruped_hrnet_w32_fasterrcnn_resnet50_fpn_v2__labeled_before_adapt.mp4'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f0ffdd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DEEPLABCUT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
