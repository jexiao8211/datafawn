{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "181b6da5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU: NVIDIA GeForce RTX 5070 Ti Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "import torch\n",
    "import datafawn\n",
    "importlib.reload(datafawn)\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "# Check GPU\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print(f\"Using GPU: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print(\"CUDA not available, using CPU\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a87f974c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============== POSE ESTIMATOR =============== #\n",
    "dlc_estimator = datafawn.DeepLabCutPoseEstimator(\n",
    "    model_name='superanimal_quadruped',\n",
    "    detector_name='fasterrcnn_resnet50_fpn_v2',\n",
    "    hrnet_model='hrnet_w32',\n",
    "    max_individuals=1,\n",
    "    pcutoff=0.15,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "# =============== POSTPROCESSORS =============== #\n",
    "rel_paws = ['front_left_paw_rel', 'front_right_paw_rel', 'back_left_paw_rel', 'back_right_paw_rel']\n",
    "reference_map = {\n",
    "    'back_base': ['front_left_paw', 'front_right_paw'],\n",
    "    'tail_base': ['back_left_paw', 'back_right_paw']\n",
    "}\n",
    "\n",
    "rel_pp = datafawn.RelativePawPositionPostprocessor()\n",
    "error_pp = datafawn.ErrorPostprocessor(\n",
    "    bodyparts=rel_paws,\n",
    "    use_velocity=True,\n",
    "    use_likelihood=True,\n",
    "    use_distance=True,\n",
    "    velocity_kwargs={'threshold_pixels': 50, 'window_size': 5},\n",
    "    likelihood_kwargs={'min_likelihood': 0.5},\n",
    "    distance_kwargs={'reference_map': reference_map, 'max_distance': 300}\n",
    ")\n",
    "\n",
    "# =============== EVENT EXTRACTOR =============== #\n",
    "zeni_extractor = datafawn.ZeniExtractor(\n",
    "    smooth_window_size=5,\n",
    "    prominence_percentage=0.05,\n",
    "    orientation_likelihood_threshold=0.0,\n",
    "    orientation_smooth_window_size=15,\n",
    "    show_plots=False\n",
    ")\n",
    "\n",
    "# =============== SOUNDSCAPE GENERATOR =============== #\n",
    "SOUNDSCAPE_CONFIG = {\n",
    "    'event_sound_map': {\n",
    "        'front_left_paw_strike': Path('data_example/sounds/22415__anthousai__wind-chimes/398494__anthousai__wind-chimes-single-01.wav'),\n",
    "        'front_right_paw_strike': Path('data_example/sounds/22415__anthousai__wind-chimes/398493__anthousai__wind-chimes-single-02.wav'),\n",
    "        'back_left_paw_strike': Path('data_example/sounds/22415__anthousai__wind-chimes/398492__anthousai__wind-chimes-single-03.wav'),\n",
    "        'back_right_paw_strike': Path('data_example/sounds/22415__anthousai__wind-chimes/398496__anthousai__wind-chimes-single-04.wav')\n",
    "    },\n",
    "    'backing_track': Path('data_example/sounds/22415__anthousai__wind-chimes/398495__anthousai__wind-chimes-rough.wav'),\n",
    "    'volume': {\n",
    "        'backing_track': 0.10,\n",
    "        'event_sounds': 0.65,\n",
    "        'original_video': 4.0\n",
    "    }\n",
    "}\n",
    "ss_generator = datafawn.SoundScapeFromConfig(soundscape_config=SOUNDSCAPE_CONFIG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45b1fa01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the FULL pipeline with all components\n",
    "pipeline = datafawn.EventDetectionPipeline(\n",
    "    pose_estimator=dlc_estimator,\n",
    "    postprocessors=[rel_pp, error_pp],\n",
    "    event_extractors=[zeni_extractor],\n",
    "    soundscape_generators=[ss_generator]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9eeffc98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading DLC 3.0.0rc13...\n",
      "Running video inference on [WindowsPath('data/raw_videos/spike_elk.mp4')] with superanimal_quadruped_hrnet_w32\n",
      "Using pytorch for model hrnet_w32\n",
      "Processing video data\\raw_videos\\spike_elk.mp4\n",
      "Starting to analyze data\\raw_videos\\spike_elk.mp4\n",
      "Video metadata: \n",
      "  Overall # of frames:    600\n",
      "  Duration of video [s]:  20.00\n",
      "  fps:                    30.0\n",
      "  resolution:             w=1296, h=720\n",
      "\n",
      "Running detector with batch size 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 600/600 [00:43<00:00, 13.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running pose prediction with batch size 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 600/600 [00:32<00:00, 18.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results to data\\spike_elk\\pose_estimation\n",
      "Saving results in data\\spike_elk\\pose_estimation\\spike_elk_superanimal_quadruped_hrnet_w32_fasterrcnn_resnet50_fpn_v2_.h5 and data\\spike_elk\\pose_estimation\\spike_elk_superanimal_quadruped_hrnet_w32_fasterrcnn_resnet50_fpn_v2__full.pickle\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jexia\\anaconda3\\envs\\DEEPLABCUT\\Lib\\site-packages\\deeplabcut\\utils\\make_labeled_video.py:146: FutureWarning: DataFrame.groupby with axis=1 is deprecated. Do `frame.T.groupby(...)` without axis instead.\n",
      "  Dataframe.groupby(level=\"individuals\", axis=1).size().values // 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duration of video [s]: 20.0, recorded with 30.0 fps!\n",
      "Overall # of frames: 600 with cropped frame dimensions: 1296 720\n",
      "Generating frames and creating video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 600/600 [00:09<00:00, 63.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video with predictions was saved as data\\spike_elk\\pose_estimation\n",
      "ðŸ“ Saved pose data: data\\spike_elk\\pose_estimation\\pose_data.h5\n",
      "Dataframe with relative positions created:\n",
      "Original shape: (600, 117)\n",
      "New shape: (600, 129)\n",
      "\n",
      "New bodyparts added:\n",
      "['back_left_paw_rel', 'back_right_paw_rel', 'front_left_paw_rel', 'front_right_paw_rel']\n",
      "ðŸ“ Saved postprocessed data: data\\spike_elk\\postprocessing\\postprocessed_data.h5\n",
      "ðŸ“ Saved events: data\\spike_elk\\events\\events.json\n",
      "Loading video: data\\spike_elk\\pose_estimation\\spike_elk_superanimal_quadruped_hrnet_w32_fasterrcnn_resnet50_fpn_v2__labeled_before_adapt.mp4\n",
      "Video FPS: 30.0\n",
      "Video duration: 20.00 seconds\n",
      "\n",
      "============================================================\n",
      "Processing individual: animal0 (scorer: superanimal_quadruped_hrnet_w32_fasterrcnn_resnet50_fpn_v2_)\n",
      "============================================================\n",
      "\n",
      "  Processing front_right_paw_strike:\n",
      "    Found 6 strikes\n",
      "    Strike timestamps: ['1.57s', '3.27s', '5.00s']...\n",
      "    Sound duration: 3.16 seconds\n",
      "    Created 6 audio clips for front_right_paw_strike\n",
      "\n",
      "  Processing back_left_paw_strike:\n",
      "    Found 9 strikes\n",
      "    Strike timestamps: ['0.67s', '2.00s', '3.40s']...\n",
      "    Sound duration: 3.19 seconds\n",
      "    Created 9 audio clips for back_left_paw_strike\n",
      "\n",
      "  Processing back_right_paw_strike:\n",
      "    Found 9 strikes\n",
      "    Strike timestamps: ['1.10s', '1.80s', '2.83s']...\n",
      "    Sound duration: 4.04 seconds\n",
      "    Created 9 audio clips for back_right_paw_strike\n",
      "\n",
      "  Processing front_left_paw_strike:\n",
      "    Found 11 strikes\n",
      "    Strike timestamps: ['0.83s', '2.43s', '4.00s']...\n",
      "    Sound duration: 5.00 seconds\n",
      "    Created 11 audio clips for front_left_paw_strike\n",
      "\n",
      "Total audio clips created: 35\n",
      "\n",
      "============================================================\n",
      "Processing backing track\n",
      "============================================================\n",
      "Backing track duration: 26.22 seconds\n",
      "Video duration: 20.00 seconds\n",
      "Backing track is longer, cropping to 20.00 seconds\n",
      "Backing track volume set to 10%\n",
      "Final backing track duration: 20.00 seconds\n",
      "No original video audio found, skipping...\n",
      "\n",
      "Writing output video to: data\\spike_elk\\soundscapes\\SoundScapeFromConfig_output.mp4\n",
      "MoviePy - Building video data\\spike_elk\\soundscapes\\SoundScapeFromConfig_output.mp4.\n",
      "MoviePy - Writing audio in SoundScapeFromConfig_outputTEMP_MPY_wvf_snd.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "MoviePy - Writing video data\\spike_elk\\soundscapes\\SoundScapeFromConfig_output.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done !\n",
      "MoviePy - video ready data\\spike_elk\\soundscapes\\SoundScapeFromConfig_output.mp4\n",
      "Done! Output saved to: data\\spike_elk\\soundscapes\\SoundScapeFromConfig_output.mp4\n",
      "ðŸ“ Saved soundscape: data\\spike_elk\\soundscapes\\SoundScapeFromConfig_output.mp4\n"
     ]
    }
   ],
   "source": [
    "# Run full pipeline from raw video\n",
    "RAW_VIDEO_PATH = 'data/raw_videos/spike_elk.mp4'\n",
    "OUTPUT_DIR = 'data/spike_elk'\n",
    "\n",
    "results = pipeline.run(\n",
    "    video_path=RAW_VIDEO_PATH,\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    soundscape_input_video=\"pose_est\"  # Use the labeled video for soundscape\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e012f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Partial pipeline after events are extracted\n",
    "results = pipeline.run(\n",
    "    events_path='data/spike_elk/events/events.json',\n",
    "    output_dir='data/soundscape_tests/',\n",
    "    soundscape_input_video='data/spike_elk/pose_estimation/spike_elk_superanimal_quadruped_hrnet_w32_fasterrcnn_resnet50_fpn_v2__labeled_before_adapt.mp4'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f0ffdd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DEEPLABCUT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
