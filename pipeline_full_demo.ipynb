{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Full Pipeline Demo\n",
        "\n",
        "This notebook demonstrates the complete pipeline workflow:\n",
        "1. **Full Pipeline** - Run from raw video through all stages\n",
        "2. **Reuse Outputs** - Use intermediate outputs as inputs to skip stages\n",
        "\n",
        "## Pipeline Stages\n",
        "```\n",
        "Video → Pose Estimation → Postprocessing → Event Extraction → Soundscape\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import importlib\n",
        "import torch\n",
        "import datafawn\n",
        "importlib.reload(datafawn)\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "# Check GPU\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device('cuda')\n",
        "    print(f\"Using GPU: {torch.cuda.get_device_name(0)}\")\n",
        "else:\n",
        "    device = torch.device('cpu')\n",
        "    print(\"CUDA not available, using CPU\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Setup: Create All Pipeline Components\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============== POSE ESTIMATOR =============== #\n",
        "dlc_estimator = datafawn.DeepLabCutPoseEstimator(\n",
        "    model_name='superanimal_quadruped',\n",
        "    detector_name='fasterrcnn_resnet50_fpn_v2',\n",
        "    hrnet_model='hrnet_w32',\n",
        "    max_individuals=1,\n",
        "    pcutoff=0.15,\n",
        "    device=device\n",
        ")\n",
        "\n",
        "# =============== POSTPROCESSORS =============== #\n",
        "rel_paws = ['front_left_paw_rel', 'front_right_paw_rel', 'back_left_paw_rel', 'back_right_paw_rel']\n",
        "reference_map = {\n",
        "    'back_base': ['front_left_paw', 'front_right_paw'],\n",
        "    'tail_base': ['back_left_paw', 'back_right_paw']\n",
        "}\n",
        "\n",
        "rel_pp = datafawn.RelativePawPositionPostprocessor()\n",
        "error_pp = datafawn.ErrorPostprocessor(\n",
        "    bodyparts=rel_paws,\n",
        "    use_velocity=True,\n",
        "    use_likelihood=True,\n",
        "    use_distance=True,\n",
        "    velocity_kwargs={'threshold_pixels': 50, 'window_size': 5},\n",
        "    likelihood_kwargs={'min_likelihood': 0.5},\n",
        "    distance_kwargs={'reference_map': reference_map, 'max_distance': 300}\n",
        ")\n",
        "\n",
        "# =============== EVENT EXTRACTOR =============== #\n",
        "zeni_extractor = datafawn.ZeniExtractor(\n",
        "    smooth_window_size=5,\n",
        "    prominence_percentage=0.05,\n",
        "    orientation_likelihood_threshold=0.0,\n",
        "    orientation_smooth_window_size=15,\n",
        "    show_plots=False\n",
        ")\n",
        "\n",
        "# =============== SOUNDSCAPE GENERATOR =============== #\n",
        "SOUNDSCAPE_CONFIG = {\n",
        "    'event_sound_map': {\n",
        "        'front_left_paw_strike': Path('data_example/sounds/22415__anthousai__wind-chimes/398494__anthousai__wind-chimes-single-01.wav'),\n",
        "        'front_right_paw_strike': Path('data_example/sounds/22415__anthousai__wind-chimes/398493__anthousai__wind-chimes-single-02.wav'),\n",
        "        'back_left_paw_strike': Path('data_example/sounds/22415__anthousai__wind-chimes/398492__anthousai__wind-chimes-single-03.wav'),\n",
        "        'back_right_paw_strike': Path('data_example/sounds/22415__anthousai__wind-chimes/398496__anthousai__wind-chimes-single-04.wav')\n",
        "    }\n",
        "}\n",
        "ss_generator = datafawn.SoundScapeFromConfig(soundscape_config=SOUNDSCAPE_CONFIG)\n",
        "\n",
        "print(\"All components created!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create the FULL pipeline with all components\n",
        "full_pipeline = datafawn.EventDetectionPipeline(\n",
        "    pose_estimator=dlc_estimator,\n",
        "    postprocessors=[rel_pp, error_pp],\n",
        "    event_extractors=[zeni_extractor],\n",
        "    soundscape_generators=[ss_generator]\n",
        ")\n",
        "\n",
        "print(\"Full pipeline ready!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Part 1: Run Full Pipeline from Video\n",
        "\n",
        "This runs ALL stages:\n",
        "- ✅ Pose Estimation (DLC)\n",
        "- ✅ Postprocessing (relative positions + error detection)\n",
        "- ✅ Event Extraction (Zeni algorithm)\n",
        "- ✅ Soundscape Generation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Run full pipeline from raw video\n",
        "RAW_VIDEO_PATH = 'data_example/raw_videos/deerrunning.mp4'\n",
        "OUTPUT_DIR = 'data/deerrunning'\n",
        "\n",
        "results = full_pipeline.run(\n",
        "    video_path=RAW_VIDEO_PATH,\n",
        "    output_dir=OUTPUT_DIR,\n",
        "    soundscape_input_video=\"pose_est\"  # Use the labeled video for soundscape\n",
        ")\n",
        "\n",
        "print(\"Full pipeline complete!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "results.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check what stages ran\n",
        "print(\"Stages executed:\")\n",
        "for stage, ran in results['metadata']['stages_run'].items():\n",
        "    status = \"✅\" if ran else \"⏭️ skipped\"\n",
        "    print(f\"  {stage}: {status}\")\n",
        "\n",
        "print(\"\\nOutput files created:\")\n",
        "for name, path in results['output_paths'].items():\n",
        "    print(f\"  {name}: {path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check the results\n",
        "print(\"Results summary:\")\n",
        "print(f\"  Pose data shape: {results['pose_data'].shape}\")\n",
        "print(f\"  Postprocessed data shape: {results['postprocessed_data'].shape}\")\n",
        "print(f\"\\nEvents extracted:\")\n",
        "for (scorer, individual), event_dict in results['events'].items():\n",
        "    print(f\"  {individual}:\")\n",
        "    for event_type, frames in event_dict.items():\n",
        "        print(f\"    {event_type}: {len(frames)} events\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Part 2: Reuse Intermediate Outputs\n",
        "\n",
        "Now let's see how to use outputs from the first run as inputs to skip stages.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Option A: Start from Pose Data (skip pose estimation)\n",
        "\n",
        "Use the pose data from the first run. This is useful when:\n",
        "- Pose estimation already done\n",
        "- Want to try different postprocessors\n",
        "- Want to experiment with different event extractors\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Option A1: Use pose_data directly from previous results (in-memory)\n",
        "results_from_pose = full_pipeline.run(\n",
        "    pose_data=results['pose_data'],\n",
        "    output_dir='full_demo_output/from_pose_data_memory',\n",
        "    soundscape_input_video='data_example/raw_videos/deerrunning.mp4'  # Need video for soundscape\n",
        ")\n",
        "\n",
        "print(\"From pose_data (in-memory):\")\n",
        "for stage, ran in results_from_pose['metadata']['stages_run'].items():\n",
        "    status = \"✅\" if ran else \"⏭️ skipped\"\n",
        "    print(f\"  {stage}: {status}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Option A2: Use pose_data_path from saved file (from disk)\n",
        "POSE_DATA_FILE = results['output_paths'].get('pose_data_file')\n",
        "print(f\"Loading from: {POSE_DATA_FILE}\")\n",
        "\n",
        "results_from_pose_file = full_pipeline.run(\n",
        "    pose_data_path=POSE_DATA_FILE,\n",
        "    output_dir='full_demo_output/from_pose_data_file',\n",
        "    soundscape_input_video='data_example/raw_videos/deerrunning.mp4'\n",
        ")\n",
        "\n",
        "print(\"\\nFrom pose_data_path (from file):\")\n",
        "for stage, ran in results_from_pose_file['metadata']['stages_run'].items():\n",
        "    status = \"✅\" if ran else \"⏭️ skipped\"\n",
        "    print(f\"  {stage}: {status}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Option B: Start from Postprocessed Data (skip pose estimation + postprocessing)\n",
        "\n",
        "Use postprocessed data. This is useful when:\n",
        "- Want to try different event extractors only\n",
        "- Already have postprocessed data from a previous run\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Option B1: Use postprocessed_data directly (in-memory)\n",
        "results_from_postproc = full_pipeline.run(\n",
        "    postprocessed_data=results['postprocessed_data'],\n",
        "    output_dir='full_demo_output/from_postprocessed_memory',\n",
        "    soundscape_input_video='data_example/raw_videos/deerrunning.mp4'\n",
        ")\n",
        "\n",
        "print(\"From postprocessed_data (in-memory):\")\n",
        "for stage, ran in results_from_postproc['metadata']['stages_run'].items():\n",
        "    status = \"✅\" if ran else \"⏭️ skipped\"\n",
        "    print(f\"  {stage}: {status}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Option B2: Use postprocessed_data_path from saved file (from disk)\n",
        "POSTPROC_FILE = results['output_paths'].get('postprocessed_data_file')\n",
        "print(f\"Loading from: {POSTPROC_FILE}\")\n",
        "\n",
        "results_from_postproc_file = full_pipeline.run(\n",
        "    postprocessed_data_path=POSTPROC_FILE,\n",
        "    output_dir='full_demo_output/from_postprocessed_file',\n",
        "    soundscape_input_video='data_example/raw_videos/deerrunning.mp4'\n",
        ")\n",
        "\n",
        "print(\"\\nFrom postprocessed_data_path (from file):\")\n",
        "for stage, ran in results_from_postproc_file['metadata']['stages_run'].items():\n",
        "    status = \"✅\" if ran else \"⏭️ skipped\"\n",
        "    print(f\"  {stage}: {status}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Option C: Start from Events (soundscape generation only)\n",
        "\n",
        "Use extracted events. This is useful when:\n",
        "- Only want to regenerate soundscape with different sounds\n",
        "- Want to try different soundscape configurations\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Option C1: Use events directly (in-memory)\n",
        "results_from_events = full_pipeline.run(\n",
        "    events=results['events'],\n",
        "    output_dir='full_demo_output/from_events_memory',\n",
        "    soundscape_input_video='data_example/raw_videos/deerrunning.mp4'\n",
        ")\n",
        "\n",
        "print(\"From events (in-memory):\")\n",
        "for stage, ran in results_from_events['metadata']['stages_run'].items():\n",
        "    status = \"✅\" if ran else \"⏭️ skipped\"\n",
        "    print(f\"  {stage}: {status}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Option C2: Use events_path from saved file (from disk)\n",
        "EVENTS_FILE = results['output_paths'].get('events_file')\n",
        "print(f\"Loading from: {EVENTS_FILE}\")\n",
        "\n",
        "results_from_events_file = full_pipeline.run(\n",
        "    events_path=EVENTS_FILE,\n",
        "    output_dir='full_demo_output/from_events_file',\n",
        "    soundscape_input_video='data_example/raw_videos/deerrunning.mp4'\n",
        ")\n",
        "\n",
        "print(\"\\nFrom events_path (from file):\")\n",
        "for stage, ran in results_from_events_file['metadata']['stages_run'].items():\n",
        "    status = \"✅\" if ran else \"⏭️ skipped\"\n",
        "    print(f\"  {stage}: {status}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Part 3: Save and Load for Later\n",
        "\n",
        "You can also use `save_results()` and `load_results()` for more control.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save all results to a specific directory\n",
        "saved_paths = full_pipeline.save_results(results, 'full_demo_output/saved_for_later')\n",
        "print(\"Saved to:\")\n",
        "for name, path in saved_paths.items():\n",
        "    print(f\"  {name}: {path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load results back in a new session\n",
        "loaded = datafawn.EventDetectionPipeline.load_results('full_demo_output/saved_for_later')\n",
        "\n",
        "print(\"Loaded:\")\n",
        "print(f\"  pose_data: {loaded['pose_data'].shape if 'pose_data' in loaded else 'None'}\")\n",
        "print(f\"  postprocessed_data: {loaded['postprocessed_data'].shape if 'postprocessed_data' in loaded else 'None'}\")\n",
        "print(f\"  events: {len(loaded.get('events', {}))} individuals\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Summary\n",
        "\n",
        "| Input Type | Stages Skipped | Stages Run |\n",
        "|------------|----------------|------------|\n",
        "| `video_path` | None | Pose Est → Postproc → Events → Soundscape |\n",
        "| `pose_data` / `pose_data_path` | Pose Est | Postproc → Events → Soundscape |\n",
        "| `postprocessed_data` / `postprocessed_data_path` | Pose Est, Postproc | Events → Soundscape |\n",
        "| `events` / `events_path` | Pose Est, Postproc, Events | Soundscape only |\n",
        "\n",
        "**In-memory vs File:**\n",
        "- Use `pose_data`, `postprocessed_data`, `events` for in-memory data (same session)\n",
        "- Use `pose_data_path`, `postprocessed_data_path`, `events_path` for data from files\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Optional: Cleanup demo output\n",
        "import shutil\n",
        "if Path('full_demo_output').exists():\n",
        "    # shutil.rmtree('full_demo_output')  # Uncomment to delete\n",
        "    print(\"Demo outputs in 'full_demo_output/' - uncomment above to delete\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "DEEPLABCUT",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
